# 可变人数支持功能说明

## 概述

EMPMP-new 模型现已支持**可变人数**，同时保持轻量化特性。模型可以处理1人、2人或3人的场景，无需重新训练或修改架构。

## 主要特性

- **动态人数**: 模型可处理1到max_p个人的输入
- **轻量设计**: 使用高效的padding和masking，无需为每个人数创建独立模型
- **向后兼容**: 现有配置和训练好的模型继续有效
- **零开销**: 使用最大人数时无额外计算成本

## 工作原理

### 核心改进

1. **最大人数参数 (`max_p`)**: 模型初始化时设置支持的最大人数（默认3人）
2. **动态填充**: 少于max_p人的输入会自动进行零填充
3. **高效处理**: 填充值不会影响实际计算
4. **智能截断**: 输出自动匹配实际人数

### 修改的组件

所有模型变体都已更新：
- `models_dual_inter` - 基础模型
- `models_dual_inter_traj` - 带轨迹特征
- `models_dual_inter_traj_out_T` - 输出轨迹
- `models_dual_inter_traj_3dpw` - 3DPW专用
- `models_dual_inter_traj_big` - 大模型
- `models_dual_inter_traj_pips` - PIPS版本

## 配置方法

在配置文件中（如 `src/baseline_h36m_30to30/config.py`）：

```python
# 设置最大人数
C.max_p = 3  # 可设置为1、2、3或更多

# 保留n_p以向后兼容
C.n_p = 3

# Motion MLP配置
C.motion_mlp.max_p = C.max_p
```

## 使用示例

### 示例1: 可变人数训练

```python
from src.models_dual_inter.model import siMLPe
from src.baseline_h36m_30to30.config import config

# 设置最大人数
config.max_p = 3
config.motion_mlp.max_p = 3

# 创建模型
model = siMLPe(config)

# 不同人数的输入都可以使用
input_1人 = torch.randn(batch_size, 1, time_steps, dim)
input_2人 = torch.randn(batch_size, 2, time_steps, dim)
input_3人 = torch.randn(batch_size, 3, time_steps, dim)

# 同一个模型处理所有输入
output_1 = model(input_1人)  # 输出形状: (batch_size, 1, time_steps, dim)
output_2 = model(input_2人)  # 输出形状: (batch_size, 2, time_steps, dim)
output_3 = model(input_3人)  # 输出形状: (batch_size, 3, time_steps, dim)
```

### 示例2: 不同人数的推理

```python
# 加载用max_p=3训练的模型
model = siMLPe(config)
model.load_state_dict(torch.load('model.pth'))
model.eval()

# 同一模型可处理1、2或3人
with torch.no_grad():
    # 单人推理
    单人输入 = get_single_person_data()  # 形状: (1, 1, T, D)
    单人输出 = model(单人输入)
    
    # 双人推理
    双人输入 = get_two_people_data()  # 形状: (1, 2, T, D)
    双人输出 = model(双人输入)
    
    # 三人推理
    三人输入 = get_three_people_data()  # 形状: (1, 3, T, D)
    三人输出 = model(三人输入)
```

## 性能特点

### 内存使用

- **存储**: 模型参数固定，与实际人数无关
- **运行时**: 内存根据max_p缩放，非实际人数
- **示例**: max_p=3的模型，处理1人、2人或3人时使用相同内存

### 计算效率

- **填充开销**: 极小 - 仅影响与人数相关的维度
- **无重复计算**: 每次forward仅填充一次
- **优化**: PyTorch的零填充操作高度优化

### 对比

| 方法 | 内存占用 | 训练灵活性 | 推理速度 |
|------|---------|-----------|---------|
| 独立模型 | 高 (3x) | 低 | 快 |
| 动态模型 (本方案) | 低 | 高 | 快 |
| 掩码注意力 | 中 | 高 | 中 |

## 技术细节

### 填充策略

使用**零填充**实现可变人数：

1. **输入阶段**: 当 P < max_p 时，输入张量被填充：
   - `x`: 从 `(B, P, D, T)` 填充到 `(B, max_p, D, T)`
   - `x_global`: 从 `(B, D, P*T)` 填充到 `(B, D, max_p*T)`
   - `distances`: 从 `(B, P, 1, T)` 填充到 `(B, max_p, 1, T)`

2. **处理阶段**: 所有计算在填充后的张量上进行

3. **输出阶段**: 移除填充维度：
   - 输出从 `(B, max_p, D, T)` 截断到 `(B, P, D, T)`

### 为什么选择零填充？

- **简单**: 易于实现和理解
- **高效**: 无需额外参数或计算
- **有效**: 零值不影响梯度或预测
- **兼容**: 与层归一化等操作无缝配合

## 注意事项

1. **最大人数设置**: 确保max_p足够大
   - 运行时不能超过max_p
   - 更大的max_p会线性增加内存使用

2. **训练数据**: 最佳效果需要混合人数训练
   - 包含1人、2人和3人的样本
   - 使用数据增强如`getRandomPermuteOrder`

3. **批处理**: 同一批次中所有样本必须有相同人数
   - 使用padding_mask处理真正的变长批次
   - 或按人数整理样本

## 常见问题

### 问题: 模型期望固定人数

**解决**: 确保配置中设置了max_p：
```python
config.max_p = 3
config.motion_mlp.max_p = 3
```

### 问题: max_p=5时内存不足

**解决**: 减小max_p或批大小。内存随max_p线性增长。

### 问题: 单人场景性能不佳

**解决**: 在训练数据中包含单人样本，或使用数据增强。

## 迁移指南

### 更新现有代码

1. **更新配置**:
   ```python
   # 添加到 config.py
   C.max_p = C.n_p  # 使用现有的n_p作为max_p
   C.motion_mlp.max_p = C.max_p
   ```

2. **无需模型修改**: 已训练的模型可直接使用

3. **可选**: 用混合人数数据重新训练以获得更好的可变人数性能

### 新项目

从一开始使用max_p：
```python
C.max_p = 3  # 期望的最大人数
C.n_p = 3     # 默认人数（可选，向后兼容）
```

## 实现细节

### 修改的文件

1. **模型文件** (所有变体的 `mlp.py`):
   - 添加`max_p`和`time_dim`实例变量
   - 修改`forward()`方法处理可变人数
   - 更新`build_mlps()`支持max_p参数

2. **配置文件** (`config.py`):
   - 添加`C.max_p`参数
   - 添加`C.motion_mlp.max_p`参数

### 关键代码位置

- 基础模型: `src/models_dual_inter/mlp.py`
- 配置: `src/baseline_h36m_30to30/config.py`
- 数据工具: `src/baseline_3dpw_big/lib/dataset/dataset_util.py`

## 总结

这个更新使EMPMP-new模型能够灵活处理不同人数的场景，同时保持：
- ✅ 轻量化设计
- ✅ 高效计算
- ✅ 向后兼容
- ✅ 易于使用

---

**详细文档**: 参见 `VARIABLE_PERSON_COUNT.md` (英文)

**问题反馈**: 请在仓库中提issue
