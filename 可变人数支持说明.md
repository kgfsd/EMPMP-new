# 多人可变人数支持 (9-15人)

本文档说明在EMPMP模型架构中实现的可变人数支持，能够动态处理9-15人，同时保持轻量级模型。

## 概述

模型现在通过填充和掩码机制支持可变人数，实现：
- **固定最大人数**：最多15人
- **动态人数**：每个场景9-15人
- **数据集内可变人数**：人员可以进出场景
- **轻量级架构**：参数在不同人数间共享

## 主要变更

### 1. 模型架构更新

#### `StylizationBlock` (在 `mlp.py` 中)
- 添加 `max_p` 参数以支持最大人数
- 修改线性层使用 `max_p` 而不是固定的 `num_p`
- 在forward方法中添加 `padding_mask` 参数
- 为少于 `max_p` 人数的输入实现填充
- 应用掩码将填充的人清零

#### `TransMLP` (在 `mlp.py` 中)
- 添加 `max_p` 参数以支持最大人数
- 全局MLP使用 `seq*max_p` 维度以适应可变人数
- forward方法将输入填充到 `max_p` 并应用掩码
- 仅处理有效人员，在输出中提取原始人数

#### `siMLPe` 模型 (在 `model.py` 中)
- 在forward方法中添加 `padding_mask` 参数
- 将掩码传递到MLP层

### 2. 数据集更新

#### `DATA` 类 (在 `dataset_mocap.py` 中)
- 添加 `max_p` 参数以支持最大人数
- 添加 `variable_persons` 标志以启用可变人数模式
- 存储 `n_p`（典型数量）和 `max_p`（最大数量）

### 3. 配置更新

要启用可变人数支持，在配置中添加：

```python
config.motion_mlp.n_p = 9  # 最小/典型人数
config.motion_mlp.max_p = 15  # 最大人数
```

## 使用示例

### 使用可变人数训练

```python
import torch
from src.models_dual_inter_traj_big.model import siMLPe

# 配置模型
config.motion_mlp.n_p = 9
config.motion_mlp.max_p = 15

model = siMLPe(config)

# 准备具有可变人数的批次（例如，10人和15人）
batch_size = 2
max_persons = 15

# 样本1：10人
motion_input_1 = torch.randn(1, 10, 30, 45)
traj_1 = torch.randn(1, 10, 30, 15, 3)
# 填充到max_persons
motion_input_1 = torch.cat([motion_input_1, torch.zeros(1, 5, 30, 45)], dim=1)
traj_1 = torch.cat([traj_1, torch.zeros(1, 5, 30, 15, 3)], dim=1)
padding_mask_1 = torch.cat([torch.ones(1, 10), torch.zeros(1, 5)], dim=1)

# 样本2：15人
motion_input_2 = torch.randn(1, 15, 30, 45)
traj_2 = torch.randn(1, 15, 30, 15, 3)
padding_mask_2 = torch.ones(1, 15)

# 合并为批次
motion_input = torch.cat([motion_input_1, motion_input_2], dim=0)
traj = torch.cat([traj_1, traj_2], dim=0)
padding_mask = torch.cat([padding_mask_1, padding_mask_2], dim=0)

# 前向传播
output = model(motion_input, traj, padding_mask=padding_mask)
# 输出形状: [2, 15, 30, 45] - 但只计算有效人员
```

### 测试不同人数

```python
# 测试不同人数
for n_persons in [9, 10, 12, 15]:
    motion_input = torch.randn(1, n_persons, 30, 45)
    traj = torch.randn(1, n_persons, 30, 15, 3)
    padding_mask = torch.ones(1, n_persons)
    
    output = model(motion_input, traj, padding_mask=padding_mask)
    print(f"成功处理 {n_persons} 人")
```

## 实现细节

### 填充策略
- 所有输入都填充到 `max_p`（15人）
- 填充位置用零填充
- 填充掩码指示有效人员（1）与填充人员（0）

### 掩码机制
- 在 `StylizationBlock` 中每次转换后应用
- 确保填充的人员不贡献梯度
- 掩码位置在整个计算过程中保持为零

### 轻量级设计
- 模型参数在所有人数间共享
- 不同人数不需要额外参数
- 全局特征维度适应 `max_p * seq_len`
- 通过仅在需要时填充来实现高效内存使用

### 向后兼容性
- 如果未指定 `max_p`，默认为 `n_p`（原始行为）
- 现有代码无需修改即可继续工作
- `padding_mask` 是可选的；如果未提供，则假设所有人员都有效

## 优势

1. **灵活性**：动态处理9-15人
2. **效率**：共享参数保持模型轻量级
3. **鲁棒性**：在同一数据集/批次中处理可变人数
4. **可扩展性**：易于调整max_p以满足不同需求

## 性能考虑

- 计算成本与 `max_p` 成比例，而不是实际人数
- 为了获得最佳性能，批次中的样本应具有相似的人数
- 对于接近 `max_p` 的数量，填充开销很小
- 内存使用与 `max_p * batch_size` 成比例

## 测试

运行测试脚本以验证可变人数支持：

```bash
python test_variable_persons.py
```

这将测试模型：
- 不同固定人数（9、12、15）
- 同一批次中的可变人数
- 填充掩码功能

## 注意事项

- 实现重点关注 `models_dual_inter_traj_big` 和 `models_dual_inter_traj_pips` 变体
- 如有需要，可以类似地更新其他模型变体
- 使用可变人数时，应修改数据集加载器以提供填充掩码

## 技术实现要点

### 关键修改的文件

1. **src/models_dual_inter_traj_big/mlp.py**
   - StylizationBlock类：添加max_p支持和掩码处理
   - TransMLP类：添加动态人数处理
   - build_mlps函数：添加max_p参数传递

2. **src/models_dual_inter_traj_big/model.py**
   - siMLPe类：添加padding_mask参数传递

3. **src/models_dual_inter_traj_pips/mlp.py**
   - 同models_dual_inter_traj_big的更改

4. **src/models_dual_inter_traj_pips/model.py**
   - 同models_dual_inter_traj_big的更改

5. **src/baseline_h36m_30to30_pips/lib/datasets/dataset_mocap.py**
   - DATA类：添加max_p和variable_persons参数

### 参数说明

- **n_p**: 典型/最小人数（例如3）
- **max_p**: 支持的最大人数（例如15）
- **padding_mask**: 形状为[B, P]的张量，1表示有效人员，0表示填充

### 使用场景

此实现特别适合：
- 场景中人数在9-15之间变化的数据集
- 需要处理人员进出的场景
- 保持模型参数量不变的情况下支持更多人数
- 批次中不同样本人数不同的训练场景
